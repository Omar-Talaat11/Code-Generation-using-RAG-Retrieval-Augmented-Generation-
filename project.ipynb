{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3764e7c8",
   "metadata": {},
   "source": [
    "## Code Generation using RAG (Retrieval-Augmented Generation) Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4772ff36",
   "metadata": {},
   "source": [
    "1- Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19eb8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and process the HumanEval dataset.\n",
    "# Extract task_id, prompt, and canonical_solution fields.\n",
    "df = pd.read_parquet(\"hf://datasets/openai/openai_humaneval/openai_humaneval/test-00000-of-00001.parquet\")[['task_id','prompt', 'canonical_solution']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19177a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>canonical_solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval/0</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval/1</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>result = []\\n    current_string = []\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval/2</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>return number % 1.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval/3</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval/4</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_id                                             prompt  \\\n",
       "0  HumanEval/0  from typing import List\\n\\n\\ndef has_close_ele...   \n",
       "1  HumanEval/1  from typing import List\\n\\n\\ndef separate_pare...   \n",
       "2  HumanEval/2  \\n\\ndef truncate_number(number: float) -> floa...   \n",
       "3  HumanEval/3  from typing import List\\n\\n\\ndef below_zero(op...   \n",
       "4  HumanEval/4  from typing import List\\n\\n\\ndef mean_absolute...   \n",
       "\n",
       "                                  canonical_solution  \n",
       "0      for idx, elem in enumerate(numbers):\\n    ...  \n",
       "1      result = []\\n    current_string = []\\n    ...  \n",
       "2                              return number % 1.0\\n  \n",
       "3      balance = 0\\n\\n    for op in operations:\\n...  \n",
       "4      mean = sum(numbers) / len(numbers)\\n    re...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0567f591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164 entries, 0 to 163\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   task_id             164 non-null    object\n",
      " 1   prompt              164 non-null    object\n",
      " 2   canonical_solution  164 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853feff",
   "metadata": {},
   "source": [
    "2- Embedding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4d58e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Batches: 100%|██████████| 6/6 [00:06<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use an open-source LLM to embed the prompt fields using BAAI/bge-large-en-v1.5\n",
    "# BAAI/bge-large-en-v1.5 is state of the art in english test embedding\n",
    "from sentence_transformers import SentenceTransformer   \n",
    "\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\").to('cuda')\n",
    "\n",
    "embeddings = embedding_model.encode(\n",
    "    df[\"prompt\"].tolist(),\n",
    "    batch_size=32,                          # You can tune this (e.g., 16/64 depending on GPU memory)\n",
    "    show_progress_bar=True,                # Optional, shows a progress bar\n",
    "    normalize_embeddings=True,\n",
    "    device='cuda'                          # Forces encoding on GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8812d623",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Collection [my_rag_collection] already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create a collection to store documents and embeddings using Chroma DB\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Chroma DB is the best for small to mid-scale RAG\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m collection = \u001b[43mchromadb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy_rag_collection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\chromadb\\api\\client.py:168\u001b[39m, in \u001b[36mClient.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m configuration_ef \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    166\u001b[39m     configuration[\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m] = embedding_function\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[32m    177\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._server,\n\u001b[32m    178\u001b[39m     model=model,\n\u001b[32m    179\u001b[39m     embedding_function=embedding_function,\n\u001b[32m    180\u001b[39m     data_loader=data_loader,\n\u001b[32m    181\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\chromadb\\api\\rust.py:227\u001b[39m, in \u001b[36mRustBindingsAPI.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    225\u001b[39m     configuration_json_str = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguration_json_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m collection_model = CollectionModel(\n\u001b[32m    231\u001b[39m     \u001b[38;5;28mid\u001b[39m=collection.id,\n\u001b[32m    232\u001b[39m     name=collection.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m     database=collection.database,\n\u001b[32m    238\u001b[39m )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection_model\n",
      "\u001b[31mInternalError\u001b[39m: Collection [my_rag_collection] already exists"
     ]
    }
   ],
   "source": [
    "# Create a collection to store documents and embeddings using Chroma DB\n",
    "# Chroma DB is the best for small to mid-scale RAG\n",
    "import chromadb\n",
    "\n",
    "collection = chromadb.Client().create_collection(name=\"my_rag_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc916931",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = df[[\"prompt\", \"canonical_solution\"]].to_dict(\"records\")\n",
    "\n",
    "collection.add(\n",
    "    ids = df[\"task_id\"].astype(str).tolist(),\n",
    "    # documents = df[\"prompt\"].tolist(),\n",
    "    metadatas = metadata,\n",
    "    embeddings = embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3afacc",
   "metadata": {},
   "source": [
    "3- Retrieval Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd790c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_nearest(query,k):\n",
    "    query_embedded = embedding_model.encode([query], normalize_embeddings=True, device='cuda')\n",
    "    result = collection.query(\n",
    "        query_embeddings=query_embedded,\n",
    "        n_results=k\n",
    "    )\n",
    "    return {\n",
    "        \"ids\": result[\"ids\"][0],\n",
    "        \"metadatas\" : result[\"metadatas\"][0],\n",
    "    } # Return the 'k' ids and solutions in a list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Retrieval Engine\n",
    "results = retrieve_nearest(df[\"prompt\"][0],3)\n",
    "# print (results[\"metadatas\"][0][\"prompt\"])\n",
    "for id in results[\"ids\"]:\n",
    "    print(f'{id}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb60b00",
   "metadata": {},
   "source": [
    "4- Code Generator using deepseek-chat-v3 from openrouter.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3934301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an open-source code generation model with coding knowledge to generate Python code using the prompt and retrieved code snippets as context.\n",
    "import requests\n",
    "\n",
    "key = \"OPENROUTER_API_KEY\"\n",
    "\n",
    "def generate_code(query, retrieved_chunks):\n",
    "    API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {key}\", \n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Combine retrieved chunks into a single string\n",
    "    # context = \"\\n\\n\".join(retrieved_chunks[\"prompt\"])\n",
    "    \n",
    "    context = \"\"\n",
    "    for entry in retrieved_chunks[\"metadatas\"]:\n",
    "        context = context + \"\\n\\n[Prompt]\\n\" + entry[\"prompt\"] + \"\\n[Solution\\n\" + entry[\"canonical_solution\"]\n",
    "    # Format RAG-style prompt\n",
    "    prompt = f\"\"\"You are a helpful coding assistant.\n",
    "\n",
    "Respond only with python code with no description or additional text.\n",
    "Use the following retrieved context to answer the user's question.\n",
    "The Context consists of a prompt and an answer\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[User Question]\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-chat-v3-0324:free\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 500  \n",
    "    }\n",
    "\n",
    "    # response = requests.post(API_URL, headers=headers, json=data)\n",
    "    count = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            count+=1\n",
    "            response = requests.post(API_URL, headers=headers, json=data)\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except:\n",
    "            if(count==5):\n",
    "                break\n",
    "            print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Code generator\n",
    "query = df[\"prompt\"][0]\n",
    "context = retrieve_nearest(query,3)\n",
    "result = generate_code(query,context)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253bae1e",
   "metadata": {},
   "source": [
    "5- Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine embedding, retrieval, and generation into a clean modular pipeline.\n",
    "# Accept a prompt ➝ retrieve similar examples ➝ generate and return new code.\n",
    "\n",
    "def RAG_pipeline(k_examples,user_input = False,prompt=\"\"):\n",
    "    if(user_input == True):\n",
    "        query = input(\"Please Enter your query\")        # Accept a prompt\n",
    "    else:\n",
    "        query = prompt\n",
    "    context = retrieve_nearest(query,k_examples)        # Retrieve similar examples\n",
    "    result = generate_code(query,context)                 # Generate and return new code.\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeeeaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"prompt\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c1322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Integration pipeline\n",
    "result = RAG_pipeline(3,True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b68837",
   "metadata": {},
   "source": [
    "6- Evaluate Performance using BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"prompt\": '''def is_palindrome_number(n: int) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if the integer n is a palindrome number (reads the same forward and backward).\n",
    "    A negative number is not considered a palindrome.\n",
    "    \"\"\"''',\n",
    "        \"canonical_solution\": '''def is_palindrome_number(n: int) -> bool:\n",
    "    if n < 0:\n",
    "        return False\n",
    "    return str(n) == str(n)[::-1]'''\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": '''def count_substring(s: str, sub: str) -> int:\n",
    "    \"\"\"\n",
    "    Return the number of non-overlapping occurrences of substring sub in string s.\n",
    "    \"\"\"''',\n",
    "        \"canonical_solution\": '''def count_substring(s: str, sub: str) -> int:\n",
    "    return s.count(sub)'''\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": '''def filter_non_negative(numbers: List[float]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Given a list of numbers, return a new list containing only the non-negative values.\n",
    "    \"\"\"''',\n",
    "        \"canonical_solution\": '''def filter_non_negative(numbers: List[float]) -> List[float]:\n",
    "    return [x for x in numbers if x >= 0]'''\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": '''def average_word_length(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Return the average word length in the input string.\n",
    "    Words are separated by spaces. If there are no words, return 0.0.\n",
    "    \"\"\"''',\n",
    "        \"canonical_solution\": '''def average_word_length(text: str) -> float:\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return 0.0\n",
    "    return sum(len(word) for word in words) / len(words)'''\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": '''def unique_sorted(items: List[int]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Return a sorted list of unique integers from the input list.\n",
    "    \"\"\"''',\n",
    "        \"canonical_solution\": '''def unique_sorted(items: List[int]) -> List[int]:\n",
    "    return sorted(set(items))'''\n",
    "    }\n",
    "]\n",
    "\n",
    "test_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc54bd18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[32m      2\u001b[39m bert_score = load(\u001b[33m\"\u001b[39m\u001b[33mbertscore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_df\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m])):\n\u001b[32m      5\u001b[39m     prediction = RAG_pipeline(\u001b[32m3\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m,test_df[\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m][example])\n\u001b[32m      6\u001b[39m     evaluation = bert_score.compute(predictions=[result], references=[test_df[\u001b[33m\"\u001b[39m\u001b[33mcanonical_solution\u001b[39m\u001b[33m\"\u001b[39m][example]], lang=\u001b[33m\"\u001b[39m\u001b[33men\u001b[39m\u001b[33m\"\u001b[39m,device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bert_score = load(\"bertscore\")\n",
    "\n",
    "for example in range(len(test_df[\"prompt\"])):\n",
    "    prediction = RAG_pipeline(3,False,test_df[\"prompt\"][example])\n",
    "    evaluation = bert_score.compute(predictions=[result], references=[test_df[\"canonical_solution\"][example]], lang=\"en\",device=\"cuda\")\n",
    "    print(f\"F1 score for example {example+1} = {evaluation['f1'][0]*100:.02f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4604c84",
   "metadata": {},
   "source": [
    "Prepare for LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to explain code\n",
    "def explain_code(code):\n",
    "    API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"You are a helpful coding explination assistant.\n",
    "\n",
    "Explain the following code with no any additional text.\n",
    "\n",
    "\n",
    "[Code]\n",
    "{code}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-chat-v3-0324:free\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 500  \n",
    "    }\n",
    "\n",
    "    count = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            count+=1\n",
    "            response = requests.post(API_URL, headers=headers, json=data)\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except:\n",
    "            if(count==5):\n",
    "                break\n",
    "            print(response.json())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ed867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to resume the same task\n",
    "def resume_code(history):\n",
    "    API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"You are a helpful coding assistant.\n",
    "    Use the provided chat history to continue helping the user based on the last human messages given\n",
    "\n",
    "Explain the following code with no any additional text.\n",
    "\n",
    "\n",
    "[Chat History]\n",
    "{history}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-chat-v3-0324:free\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 500  \n",
    "    }\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            count+=1\n",
    "            response = requests.post(API_URL, headers=headers, json=data)\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except:\n",
    "            if(count==5):\n",
    "                break\n",
    "            print(response.json())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa05a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to explain code depending on history \n",
    "def explain_code_with_history(history):\n",
    "    API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"You are a helpful coding explination assistant.\n",
    "Provided chat history for context and the last massage describes the needed task.\n",
    "Explain the code with no any additional text.\n",
    "\n",
    "\n",
    "[History]\n",
    "{history}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-chat-v3-0324:free\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 500  \n",
    "    }\n",
    "\n",
    "    count = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            count+=1\n",
    "            response = requests.post(API_URL, headers=headers, json=data)\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except:\n",
    "            if(count==5):\n",
    "                break\n",
    "            print(response.json())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5abeaa",
   "metadata": {},
   "source": [
    "### LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ec824",
   "metadata": {},
   "source": [
    "First Structure - Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adcf3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Define graph state class\n",
    "class modelState(TypedDict):\n",
    "    input : str\n",
    "    func : str\n",
    "    result : str\n",
    "\n",
    "# Define graph runnables\n",
    "def chat(state: modelState) -> modelState:\n",
    "    \"\"\"Function to take input from user\"\"\"\n",
    "    \n",
    "    # # Input from user\n",
    "    # state[\"func\"] = input(\"Please state whether you want to generate code or explain your code\")\n",
    "    \n",
    "    # if(\"explain\" in state[\"func\"]):\n",
    "    #     state[\"input\"] = input(\"Please enter the code you want its description\")\n",
    "    # elif(\"generate\" in state[\"func\"]):\n",
    "    #     state[\"input\"] = input(\"Please enter the code description\")\n",
    "    \n",
    "    # Input from code\n",
    "    \n",
    "    return state\n",
    "\n",
    "def router(state: modelState) -> modelState:\n",
    "    \"\"\"Function to select the next node of the graph\"\"\"\n",
    "    if(\"explain\" in state[\"func\"]):\n",
    "        return \"explain_task\"\n",
    "    elif(\"generate\" in state[\"func\"]):\n",
    "        return \"generate_task\"\n",
    "        \n",
    "def generate(state: modelState) -> modelState:\n",
    "    \"\"\"Function to generate code based on input from user using RAG model\"\"\"\n",
    "    state[\"result\"]  = RAG_pipeline(3,False,state[\"input\"])\n",
    "    return state\n",
    "\n",
    "def explain(state: modelState) -> modelState:\n",
    "    \"\"\"Function to explain code provided by the user using LLM model\"\"\"\n",
    "    state[\"result\"]  = explain_code(state[\"input\"])\n",
    "    return state\n",
    "    \n",
    "# Define graph object\n",
    "graph = StateGraph(modelState)\n",
    "\n",
    "# Define graph nodes\n",
    "graph.add_node(\"chat\",chat)\n",
    "graph.add_node(\"generate_code\",generate)\n",
    "graph.add_node(\"explain_code\",explain)\n",
    "graph.add_node(\"router\", lambda state:state)\n",
    "\n",
    "# Define graph edges\n",
    "graph.add_edge(START,\"chat\")\n",
    "graph.add_edge(\"chat\",\"router\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    router, \n",
    "    {\n",
    "        # Edge: Node\n",
    "        \"explain_task\": \"explain_code\",\n",
    "        \"generate_task\": \"generate_code\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"generate_code\",END)\n",
    "graph.add_edge(\"explain_code\",END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf479d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png())) # Display structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04f28279",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test using custom input\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m custom_input= modelState(\u001b[38;5;28minput\u001b[39m=\u001b[43mtest_df\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m],func=\u001b[33m\"\u001b[39m\u001b[33mI want to generate code\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# output = app.invoke({})\u001b[39;00m\n\u001b[32m      5\u001b[39m output = app.invoke(custom_input)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Test using custom input\n",
    "custom_input= modelState(input=test_df[\"prompt\"][0],func=\"I want to generate code\")\n",
    "\n",
    "# output = app.invoke({})\n",
    "output = app.invoke(custom_input)\n",
    "print(output[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4398c3",
   "metadata": {},
   "source": [
    "Second Structure - Using tools with manual invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9924256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# Define graph state class\n",
    "class modelState2(TypedDict):\n",
    "    input : str\n",
    "    func : str\n",
    "    result : str\n",
    "\n",
    "@tool\n",
    "def generator_tool(query: str)->str:\n",
    "    \"\"\" This tool generates code using an input query \"\"\"\n",
    "    return RAG_pipeline(3,False,query)\n",
    "\n",
    "@tool\n",
    "def explainer_tool(code: str)->str:\n",
    "    \"\"\" This tool explains code given by the user \"\"\"\n",
    "    return explain_code(code)\n",
    "\n",
    "# Define graph runnables\n",
    "def chat2(state: modelState2) -> modelState2:\n",
    "    \"\"\"Function to take input from user\"\"\"\n",
    "    \n",
    "    # # Input from user\n",
    "    # state[\"func\"] = input(\"Please state whether you want to generate code or explain your code\")\n",
    "    \n",
    "    # if(\"explain\" in state[\"func\"]):\n",
    "    #     state[\"input\"] = input(\"Please enter the code you want its description\")\n",
    "    #     state[\"result\"] = explainer_tool.invoke({\"code\" : state[\"input\"]})\n",
    "    # elif(\"generate\" in state[\"func\"]):\n",
    "    #     state[\"input\"] = input(\"Please enter the code description\")\n",
    "    #     state[\"result\"] = generator_tool.invoke({\"query\" : state[\"input\"]})\n",
    "    \n",
    "    # Input from code\n",
    "    if(\"explain\" in state[\"func\"]):\n",
    "        state[\"result\"] = explainer_tool.invoke({\"code\" : state[\"input\"]})\n",
    "    elif(\"generate\" in state[\"func\"]):\n",
    "        state[\"result\"] = generator_tool.invoke({\"query\" : state[\"input\"]})\n",
    "    return state\n",
    "    \n",
    "# Define graph object\n",
    "graph2 = StateGraph(modelState2)\n",
    "\n",
    "# Define graph nodes\n",
    "graph2.add_node(\"chat\",chat2)\n",
    "\n",
    "# Define graph edges\n",
    "graph2.add_edge(START,\"chat\")\n",
    "\n",
    "graph2.add_edge(\"chat\",END)\n",
    "\n",
    "app2 = graph2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99355fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app2.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a22637",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = app2.invoke(custom_input)\n",
    "print(output2[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2651ce2",
   "metadata": {},
   "source": [
    "Third Structure - Using tools with automatic invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a909fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# Define graph state class\n",
    "class modelState3(TypedDict):\n",
    "    input : str\n",
    "    func : str\n",
    "    result : str\n",
    "\n",
    "@tool\n",
    "def generator_tool3(query: str)->str:\n",
    "    \"\"\" This tool generates code using an input query \"\"\"\n",
    "    return RAG_pipeline(3,False,query)\n",
    "\n",
    "@tool\n",
    "def explainer_tool3(code: str)->str:\n",
    "    \"\"\" This tool explains code given by the user \"\"\"\n",
    "    return explain_code(code)\n",
    "\n",
    "tools = [generator_tool3,explainer_tool3]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=\"API_KEY\"\n",
    ").bind_tools(tools)\n",
    "\n",
    "# Define graph runnables\n",
    "def chat3(state: modelState3) -> modelState3:\n",
    "    \"\"\"Function to take input from user\"\"\"\n",
    "    \n",
    "    # # Input from user\n",
    "    # state[\"func\"] = input(\"Please state whether you want to generate code or explain your code\")\n",
    "    \n",
    "    # if(\"explain\" in state[\"func\"]):\n",
    "    #     state[\"input\"] = input(\"Please enter the code you want its description\")\n",
    "    # elif(\"generate\" in state[\"func\"]):\n",
    "    #     state[\"input\"] = input(\"Please enter the code description\")\n",
    "    \n",
    "    # Input from code\n",
    "    \n",
    "    prompt = (f\"\"\"\n",
    "    You are a code generator or code explainer.\n",
    "    - 'generator_tool3' tool with the complete description provided to generate code.\n",
    "    - 'explainer_tool3' tool with the complete code given to explain code.\n",
    "    \n",
    "    The current user prompt is:{state[\"input\"]}\n",
    "    \"\"\")\n",
    "    response = llm.invoke(prompt)\n",
    "    state[\"result\"] = response.content\n",
    "    print(f\"\\n🤖 AI: {response.content}\")\n",
    "# Define graph object\n",
    "graph3 = StateGraph(modelState3)\n",
    "\n",
    "# Define graph nodes\n",
    "graph3.add_node(\"chat\",chat3)\n",
    "\n",
    "# Define graph edges\n",
    "graph3.add_edge(START,\"chat\")\n",
    "\n",
    "graph3.add_edge(\"chat\",END)\n",
    "\n",
    "app3 = graph3.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app3.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead35973",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_input= modelState3(input=test_df[\"prompt\"][0],func=\"I want to generate code\")\n",
    "app3.invoke(custom_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31dd97c",
   "metadata": {},
   "source": [
    "Fourth Structure - Using Resume node to handle extended tasks with history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91b990e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from typing import List, Union\n",
    "\n",
    "# Define graph state class\n",
    "class modelState(TypedDict):\n",
    "    messages : List[Union[HumanMessage, AIMessage]]\n",
    "\n",
    "# Define graph runnables\n",
    "def chat(state: modelState) -> modelState:\n",
    "    \"\"\"Function to take input from user\"\"\"\n",
    "    \n",
    "    # # Input from user\n",
    "    \n",
    "    \n",
    "    # state[\"func\"] = input(\"Please state whether you want to generate code or explain your code\")\n",
    "    \n",
    "    # if(\"explain\" in state[\"func\"]):\n",
    "    #     input = input(\"Please enter the code you want its description\")\n",
    "    #     state[\"messages\"].append(HumanMessage(content=input))\n",
    "    # elif(\"generate\" in state[\"func\"]):\n",
    "    #     input = input(\"Please enter the code description\")\n",
    "    #     state[\"messages\"].append(HumanMessage(content=input))\n",
    "    \n",
    "    # Input from code\n",
    "    \n",
    "    return state\n",
    "\n",
    "def router(state: modelState) -> modelState:\n",
    "    \"\"\"Function to select the next node of the graph\"\"\"\n",
    "    if(\"explain\" in state['messages'][-1].content):\n",
    "        return \"explain_task\"\n",
    "    elif(\"generate\" in state['messages'][-1].content):\n",
    "        return \"generate_task\"\n",
    "    else:\n",
    "        return \"resume_task\"\n",
    "        \n",
    "def generate(state: modelState) -> modelState:\n",
    "    \"\"\"Function to generate code based on input from user using RAG model\"\"\"\n",
    "    print(f\"\\nHuman: {state['messages'][-1].content}\")\n",
    "    state[\"messages\"].append(AIMessage(content=RAG_pipeline(3,False,str(state['messages'][-1]))))\n",
    "    print(f\"\\nAI: {state['messages'][-1].content}\")\n",
    "    return state\n",
    "\n",
    "def explain(state: modelState) -> modelState:\n",
    "    \"\"\"Function to explain code provided by the user using LLM model\"\"\"\n",
    "    print(f\"\\nHuman: {state['messages'][-1].content}\")\n",
    "    state[\"messages\"].append(AIMessage(content=explain_code_with_history(state['messages'])))\n",
    "    print(f\"\\nAI: {state['messages'][-1].content}\")\n",
    "    return state\n",
    "\n",
    "def resume(state: modelState) -> modelState:\n",
    "    \"\"\"Function to resume the same task provided by the user\"\"\"\n",
    "    print(f\"\\nHuman: {state['messages'][-1].content}\")\n",
    "    state['messages'].append(AIMessage(content=resume_code(state['messages'])))\n",
    "    print(f\"\\nAI: {state['messages'][-1].content}\")\n",
    "    return state\n",
    "# Define graph object\n",
    "graph = StateGraph(modelState)\n",
    "\n",
    "# Define graph nodes\n",
    "graph.add_node(\"chat\",chat)\n",
    "graph.add_node(\"generate_code\",generate)\n",
    "graph.add_node(\"explain_code\",explain)\n",
    "graph.add_node(\"resume_code\",resume)\n",
    "graph.add_node(\"router\", lambda state:state)\n",
    "\n",
    "# Define graph edges\n",
    "graph.add_edge(START,\"chat\")\n",
    "graph.add_edge(\"chat\",\"router\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    router, \n",
    "    {\n",
    "        # Edge: Node\n",
    "        \"explain_task\": \"explain_code\",\n",
    "        \"generate_task\": \"generate_code\",\n",
    "        \"resume_task\": \"resume_code\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"generate_code\",END)\n",
    "graph.add_edge(\"explain_code\",END)\n",
    "graph.add_edge(\"resume_code\",END)\n",
    "\n",
    "app4 = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app4.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history : List[Union[HumanMessage, AIMessage]] = []\n",
    "\n",
    "\n",
    "user_input = test_df[\"prompt\"][0] # Custom initial input\n",
    "while user_input != \"exit\": # Maintain a loop that interacts with the user naturally\n",
    "    conversation_history.append(HumanMessage(content=user_input))\n",
    "    output = app4.invoke(modelState(messages=conversation_history))\n",
    "    conversation_history = output[\"messages\"]\n",
    "    user_input = input(\"Enter: \")\n",
    "\n",
    "# Save output in log file\n",
    "with open(\"logging.text\",'w') as file:\n",
    "    file.write(\"Conversation Log:\\n\")\n",
    "    for message in conversation_history:\n",
    "        if isinstance(message,HumanMessage):\n",
    "            file.write(f\"You: {message.content}\\n\")\n",
    "        elif isinstance(message, AIMessage):\n",
    "            file.write(f\"AI: {message.content}\\n\\n\")\n",
    "    file.write(\"End of Conversation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996e887",
   "metadata": {},
   "source": [
    "Smart Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fd3c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smartRouter(history):\n",
    "# Define a function to smart route the langGraph depending on history \n",
    "    API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "# Provide just the task and user input in the following json format {'task : task,  user_input : user_input'}\".\n",
    "    # print(\"Router:\")\n",
    "    # print(history)\n",
    "    hist = \"\"\n",
    "    for i,message in enumerate(history):\n",
    "        try:\n",
    "            if(i%2==0):\n",
    "                hist = hist + \"Human: \" + message.content + '\\n'\n",
    "            else:\n",
    "                hist = hist + \"AI: \" + message.content + '\\n'\n",
    "        except:\n",
    "             hist = hist + message + '\\n'\n",
    "            \n",
    "            \n",
    "    prompt = f\"\"\"\n",
    "You are a smart router to decide the next task based on user prompt.\n",
    "You are provided with conversation history, use the last Human message to identify the needed task and the history for context.\n",
    "\n",
    "Your job is to classify the following user input as one of the following 3 tasks:\n",
    "- **generate code**\n",
    "- **explain code**\n",
    "- **resume conversation**\n",
    "\n",
    "Rules:\n",
    "- If the user provides a **code description**, or a **partial/incomplete code** (e.g., missing function body, TODOs, comments like \"please complete\"), classify it as **generate code**.\n",
    "- If the user provides a **complete piece of code** and is asking to understand or describe it, classify it as **explain code**.\n",
    "- If the user does not ask a new question but refers to a **previous conversation**, classify it as **resume conversation**.\n",
    "\n",
    "Respond only with one of the following **three exact outputs**:\n",
    "generate code, explain code, or resume conversation.\n",
    "### Examples:\n",
    "\n",
    "[Prompt]\n",
    "\\\"\"\"Write a function that checks if a number is prime.\\\"\"\"\n",
    "→ generate code\n",
    "\n",
    "[Prompt]\n",
    "\\\"\"\"def is_prime(n):\\n    # complete this function\\n    \\\"\"\"\n",
    "→ generate code\n",
    "\n",
    "[Prompt]\n",
    "\\\"\"\"Can you explain how this sorting function works?\\n\\ndef bubble_sort(arr): ...\\\"\"\"\n",
    "→ explain code\n",
    "\n",
    "[Prompt]\n",
    "\\\"\"\"Let's continue from the last thing we talked about regarding optimization.\\\"\"\"\n",
    "→ resume conversation\n",
    "\n",
    "[Prompt]\n",
    "\\\"\"\"do something with things you wrote before.\\\"\"\"\n",
    "→ resume conversation\n",
    "\n",
    "Now classify this:\n",
    "\n",
    "[History]\n",
    "{hist}\n",
    "\n",
    "\"\"\"\n",
    "    # print(prompt)\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-chat-v3-0324:free\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 500  \n",
    "    }\n",
    "\n",
    "    count = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            count+=1\n",
    "            response = requests.post(API_URL, headers=headers, json=data)\n",
    "            # print(response.json())\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except:\n",
    "            if(count==5):\n",
    "                break\n",
    "            print(response.json())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abaa12bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate code\n",
      "resume conversation\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"from typing import List\n",
    "\n",
    "Complete this function\n",
    "\n",
    "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
    "    \"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
    "    given threshold.\n",
    "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
    "    False\n",
    "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
    "    True\n",
    "    \"\"\n",
    "\"\"\"\n",
    "print(smartRouter(prompt))\n",
    "print(smartRouter(\"modify the function you just wrote\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1b3f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from typing import List, Union\n",
    "\n",
    "# Define graph state class\n",
    "class modelState(TypedDict):\n",
    "    messages : List[Union[HumanMessage, AIMessage]]\n",
    "\n",
    "# Define graph runnables\n",
    "def chat(state: modelState) -> modelState:\n",
    "    \"\"\"Function to take input from user\"\"\"\n",
    "    \n",
    "    # # Input from user\n",
    "    \n",
    "    \n",
    "    # state[\"func\"] = input(\"Please state whether you want to generate code or explain your code\")\n",
    "    \n",
    "    # if(\"explain\" in state[\"func\"]):\n",
    "    #     input = input(\"Please enter the code you want its description\")\n",
    "    #     state[\"messages\"].append(HumanMessage(content=input))\n",
    "    # elif(\"generate\" in state[\"func\"]):\n",
    "    #     input = input(\"Please enter the code description\")\n",
    "    #     state[\"messages\"].append(HumanMessage(content=input))\n",
    "    \n",
    "    # Input from code\n",
    "    \n",
    "    return state\n",
    "\n",
    "def smartrouter(state: modelState) -> modelState:\n",
    "    \"\"\"Function to select the next node of the graph\"\"\"\n",
    "    # print(\"Graph:\")\n",
    "    # print(state[\"messages\"])\n",
    "    result = smartRouter(state[\"messages\"])\n",
    "    # print(state)\n",
    "    # print(f\"Task needed: {result}\")\n",
    "    if result == \"explain code\":\n",
    "        return \"explain_code\"\n",
    "    elif result == \"generate code\":\n",
    "        return \"generate_code\"\n",
    "    elif result == \"resume conversation\":\n",
    "        return \"resume_code\"\n",
    "    \n",
    "        \n",
    "def generate(state: modelState) -> modelState:\n",
    "    \"\"\"Function to generate code based on input from user using RAG model\"\"\"\n",
    "    print(f\"\\nHuman: {state['messages'][-1].content}\")\n",
    "    state[\"messages\"].append(AIMessage(content=RAG_pipeline(3,False,str(state['messages'][-1]))))\n",
    "    print(f\"\\nAI: {state['messages'][-1].content}\")\n",
    "    # print(\"generate\")\n",
    "    return state\n",
    "\n",
    "def explain(state: modelState) -> modelState:\n",
    "    \"\"\"Function to explain code provided by the user using LLM model\"\"\"\n",
    "    print(f\"\\nHuman: {state['messages'][-1].content}\")\n",
    "    state[\"messages\"].append(AIMessage(content=explain_code_with_history(state['messages'])))\n",
    "    print(f\"\\nAI: {state['messages'][-1].content}\")\n",
    "    # print(\"explain\")\n",
    "    return state\n",
    "\n",
    "def resume(state: modelState) -> modelState:\n",
    "    \"\"\"Function to resume the same task provided by the user\"\"\"\n",
    "    print(f\"\\nHuman: {state['messages'][-1].content}\")\n",
    "    state['messages'].append(AIMessage(content=resume_code(state['messages'])))\n",
    "    print(f\"\\nAI: {state['messages'][-1].content}\")\n",
    "    # print(\"resume\")\n",
    "    return state\n",
    "# Define graph object\n",
    "graph = StateGraph(modelState)\n",
    "\n",
    "# Define graph nodes\n",
    "graph.add_node(\"chat\",chat)\n",
    "graph.add_node(\"generate_code\",generate)\n",
    "graph.add_node(\"explain_code\",explain)\n",
    "graph.add_node(\"resume_code\",resume)\n",
    "graph.add_node(\"router\", lambda state: state)\n",
    "\n",
    "# Define graph edges\n",
    "graph.add_edge(START,\"chat\")\n",
    "graph.add_edge(\"chat\", \"router\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"router\", \n",
    "    smartrouter, \n",
    "{\n",
    "    \"explain_code\": \"explain_code\",\n",
    "    \"generate_code\": \"generate_code\",\n",
    "    \"resume_code\": \"resume_code\"\n",
    "})\n",
    "\n",
    "graph.add_edge(\"generate_code\",END)\n",
    "graph.add_edge(\"explain_code\",END)\n",
    "graph.add_edge(\"resume_code\",END)\n",
    "\n",
    "app5 = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77507e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(app5.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e3174",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history : List[Union[HumanMessage, AIMessage]] = []\n",
    "\n",
    "\n",
    "user_input = test_df[\"prompt\"][0] # Custom initial input\n",
    "while user_input != \"exit\": # Maintain a loop that interacts with the user naturally\n",
    "    conversation_history.append(HumanMessage(content=user_input))\n",
    "    output = app5.invoke(modelState(messages=conversation_history))\n",
    "    conversation_history = output[\"messages\"]\n",
    "    user_input = input(\"Enter: \")\n",
    "\n",
    "# Save output in log file\n",
    "with open(\"logging.text\",'w') as file:\n",
    "    file.write(\"Conversation Log:\\n\")\n",
    "    for message in conversation_history:\n",
    "        if isinstance(message,HumanMessage):\n",
    "            file.write(f\"You: {message.content}\\n\")\n",
    "        elif isinstance(message, AIMessage):\n",
    "            file.write(f\"AI: {message.content}\\n\\n\")\n",
    "    file.write(\"End of Conversation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae372376",
   "metadata": {},
   "source": [
    "Deployment with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3cf014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_9324\\2708235937.py:26: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Provider returned error', 'code': 524, 'metadata': {'raw': 'error code: 524', 'provider_name': 'Targon'}}, 'user_id': 'user_30CBUFyjisNwIyE97GpqwEuu3jU'}\n",
      "\n",
      "Human: generate a function that prints even numbers only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: ```python\n",
      "def print_even_numbers(numbers):\n",
      "    for num in numbers:\n",
      "        if num % 2 == 0:\n",
      "            print(num)\n",
      "```\n",
      "\n",
      "Human: in the function you wrote, print omar at its end\n",
      "\n",
      "AI: ```python\n",
      "def print_even_numbers(numbers):\n",
      "    for num in numbers:\n",
      "        if num % 2 == 0:\n",
      "            print(num)\n",
      "    print(\"omar\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "langchain_history = []\n",
    "\n",
    "def respond(message, chat_history):\n",
    "    \n",
    "    # Append latest user message\n",
    "    langchain_history.append(HumanMessage(content=message))\n",
    "\n",
    "    # Prepare input for LangGraph\n",
    "    state_input = modelState(messages = langchain_history)\n",
    "\n",
    "    # Invoke LangGraph app\n",
    "    result = app5.invoke(state_input)\n",
    "\n",
    "    # Get latest AI message\n",
    "    response = result[\"messages\"][-1].content\n",
    "\n",
    "    # Add to Gradio-friendly chat history\n",
    "    chat_history.append((message, response))\n",
    "\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as interface:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    state = gr.State([])\n",
    "\n",
    "    msg.submit(respond, [msg, state], [msg, chatbot])\n",
    "    clear.click(lambda: None, None, chatbot)\n",
    "\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0340a",
   "metadata": {},
   "source": [
    "RAG Evaluation on MBPP Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   task_id                                               text  \\\n",
      "0        1  Write a function to find the minimum cost path...   \n",
      "1        2  Write a function to find the similar elements ...   \n",
      "2        3  Write a python function to identify non-prime ...   \n",
      "3        4  Write a function to find the largest integers ...   \n",
      "4        5  Write a function to find the number of ways to...   \n",
      "\n",
      "                                                code  \\\n",
      "0  R = 3\\r\\nC = 3\\r\\ndef min_cost(cost, m, n): \\r...   \n",
      "1  def similar_elements(test_tup1, test_tup2):\\r\\...   \n",
      "2  import math\\r\\ndef is_not_prime(n):\\r\\n    res...   \n",
      "3  import heapq as hq\\r\\ndef heap_queue_largest(n...   \n",
      "4  def count_ways(n): \\r\\n\\tA = [0] * (n + 1) \\r\\...   \n",
      "\n",
      "                                           test_list  \n",
      "0  [assert min_cost([[1, 2, 3], [4, 8, 2], [1, 5,...  \n",
      "1  [assert similar_elements((3, 4, 5, 6),(5, 7, 4...  \n",
      "2  [assert is_not_prime(2) == False, assert is_no...  \n",
      "3  [assert heap_queue_largest( [25, 35, 22, 85, 1...  \n",
      "4  [assert count_ways(2) == 3, assert count_ways(...  \n"
     ]
    }
   ],
   "source": [
    "# Use the [MBPP dataset](10 examples)\n",
    "# Each has: `task_id`, `prompt`, `code_solution`, and test cases.\n",
    "\n",
    "mbpp_df = pd.read_json(\"mbpp.jsonl\", lines=True)[0:10][[\"task_id\",\"text\",\"code\",\"test_list\"]]\n",
    "\n",
    "print(mbpp_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0abebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Internal Server Error', 'code': 500}}\n",
      "{'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'deepseek/deepseek-chat-v3-0324:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Chutes'}}, 'user_id': 'user_309iKOus8YmjhceykAPZmSHCmx7'}\n"
     ]
    }
   ],
   "source": [
    "# For each prompt:\n",
    "# - Retrieve similar examples using embedding similarity\n",
    "# - Feed to the LLM for completion (RAG style).\n",
    "\n",
    "solutions = []\n",
    "for p in mbpp_df[\"text\"].tolist():\n",
    "    r = RAG_pipeline(3,False,p)\n",
    "    solutions.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e086d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for example 1 = 87.66 %\n",
      "F1 score for example 2 = 85.54 %\n",
      "F1 score for example 3 = 93.19 %\n",
      "F1 score for example 4 = 90.30 %\n",
      "F1 score for example 5 = 86.02 %\n",
      "F1 score for example 6 = 88.43 %\n",
      "F1 score for example 7 = 93.44 %\n",
      "F1 score for example 8 = 88.55 %\n",
      "F1 score for example 9 = 93.38 %\n",
      "F1 score for example 10 = 85.95 %\n"
     ]
    }
   ],
   "source": [
    "# Measure Retrieval quality using F1 score\n",
    "for example in range(len(solutions)):\n",
    "    evaluation = bert_score.compute(predictions=[solutions[example]], references=[mbpp_df[\"code\"][example]], lang=\"en\",device=\"cuda\")\n",
    "    print(f\"F1 score for example {example+1} = {evaluation['f1'][0]*100:.02f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename functions to make them match\n",
    "import re\n",
    "names_replaces =[\n",
    "    [\"minPathCost\",\"min_cost\"],\n",
    "    [\"find_similar_elements\",\"similar_elements\"],\n",
    "    [\"is_non_prime\",\"is_not_prime\"],\n",
    "    [\"heap_queue_largest_numbers\",\"heap_queue_largest\"],\n",
    "    [\"domino_tiling\",\"count_ways\"],\n",
    "    [\"differ_at_one_bit\",\"differ_At_One_Bit_Pos\"],\n",
    "    [\"find_long_words\",\"find_char_long\"],\n",
    "    [\"square_list\",\"square_nums\"],\n",
    "    [\"min_rotations\",\"find_Rotations\"],\n",
    "    [\"n_smallest\",\"small_nnum\"],\n",
    "]\n",
    "for i,names in enumerate(names_replaces):\n",
    "    solutions[i] = re.sub(names[0],names[1],solutions[i])\n",
    "\n",
    "# remove markdown formatting \n",
    "solutions = [s.replace(\"```python\", \"\").replace(\"```\", \"\").strip() for s in solutions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d96bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the functions generated\n",
    "for solution in solutions:\n",
    "    exec(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab770329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Function 1 failed an assertion in test 1\n",
      "❌ Function 1 failed an assertion in test 2\n",
      "❌ Function 1 failed an assertion in test 3\n",
      "❌ Function 2 failed an assertion in test 1\n",
      "❌ Function 2 failed an assertion in test 2\n",
      "❌ Function 2 failed an assertion in test 3\n",
      "✅ Function 2 passed all tests\n",
      "✅ Function 3 passed all tests\n",
      "✅ Function 4 passed all tests\n",
      "✅ Function 5 passed all tests\n",
      "✅ Function 6 passed all tests\n",
      "✅ Function 7 passed all tests\n",
      "✅ Function 8 passed all tests\n",
      "✅ Function 9 passed all tests\n"
     ]
    }
   ],
   "source": [
    "# Measure Pass/Fail on test cases\n",
    "for i,tests in enumerate(mbpp_df[\"test_list\"]):\n",
    "    failed = False\n",
    "    \n",
    "    for j, test in enumerate(tests):\n",
    "        try:\n",
    "            exec(test)\n",
    "        except AssertionError:\n",
    "            print(f\"❌ Function {i+1} failed an assertion in test {j+1}\")\n",
    "            failed = True\n",
    "    if(failed==False):\n",
    "        print(f\"✅ Function {i} passed all tests\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ea9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def min_cost(cost, m, n):\n",
      "    rows = len(cost)\n",
      "    cols = len(cost[0]) if rows > 0 else 0\n",
      "    \n",
      "    dp = [[0 for _ in range(cols)] for _ in range(rows)]\n",
      "    dp[0][0] = cost[0][0]\n",
      "    \n",
      "    for i in range(1, rows):\n",
      "        dp[i][0] = dp[i-1][0] + cost[i][0]\n",
      "    \n",
      "    for j in range(1, cols):\n",
      "        dp[0][j] = dp[0][j-1] + cost[0][j]\n",
      "    \n",
      "    for i in range(1, rows):\n",
      "        for j in range(1, cols):\n",
      "            dp[i][j] = min(dp[i-1][j], dp[i][j-1]) + cost[i][j]\n",
      "    \n",
      "    return dp[m][n]\n",
      "R = 3\n",
      "C = 3\n",
      "def min_cost(cost, m, n): \n",
      "\ttc = [[0 for x in range(C)] for x in range(R)] \n",
      "\ttc[0][0] = cost[0][0] \n",
      "\tfor i in range(1, m+1): \n",
      "\t\ttc[i][0] = tc[i-1][0] + cost[i][0] \n",
      "\tfor j in range(1, n+1): \n",
      "\t\ttc[0][j] = tc[0][j-1] + cost[0][j] \n",
      "\tfor i in range(1, m+1): \n",
      "\t\tfor j in range(1, n+1): \n",
      "\t\t\ttc[i][j] = min(tc[i-1][j-1], tc[i-1][j], tc[i][j-1]) + cost[i][j] \n",
      "\treturn tc[m][n]\n",
      "def similar_elements(t1: tuple, t2: tuple) -> list:\n",
      "    ret = set()\n",
      "    for e1 in t1:\n",
      "        for e2 in t2:\n",
      "            if e1 == e2:\n",
      "                ret.add(e1)\n",
      "    return sorted(list(ret))\n",
      "def similar_elements(test_tup1, test_tup2):\n",
      "  res = tuple(set(test_tup1) & set(test_tup2))\n",
      "  return (res) \n"
     ]
    }
   ],
   "source": [
    "# Examine Failed Functions\n",
    "print(solutions[0])\n",
    "print(mbpp_df[\"code\"][0])\n",
    "# Generated function restricts diagonal moves but original function allows them\n",
    "\n",
    "print(solutions[1])\n",
    "print(mbpp_df[\"code\"][1])\n",
    "# Generated function restricts cares about order but original function doesn't order the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96d290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
